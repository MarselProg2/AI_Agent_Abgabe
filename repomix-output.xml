This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.gitignore
.python-version
Antipasti_Zutaten_Video_Generiert.mp4
app.py
penguin.mp4
pyproject.toml
README.md
root_agent/__init__.py
root_agent/.adk/eval_history/root_agent_evalset1_test_1770929057.6514924.evalset_result.json
root_agent/.gitignore
root_agent/agent.py
root_agent/evalset1_test.evalset.json
root_agent/output_structure.py
root_agent/subagents/__init__.py
root_agent/subagents/creation_evaluation_loop.py
root_agent/subagents/creator_agent.py
root_agent/subagents/evaluator_agent.py
root_agent/subagents/insight_extractor_agent.py
root_agent/subagents/video_analyst_agent.py
root_agent/test/msg.py
root_agent/test/scenarios_test.json
root_agent/test/testmsg.py
root_agent/tools/__init__.py
root_agent/tools/engagement.py
root_agent/tools/exit_loop.py
test_output.txt
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="root_agent/output_structure.py">
"""
Pydantic Output Schemas for the InsightBench Multi-Agent System.
Each schema defines the structured output format for the corresponding agent.
"""

from typing import List, Optional
from pydantic import BaseModel, Field


# ============================================================================
# Schema: Video Analyst Agent
# ============================================================================
class SchemaExtraction(BaseModel):
    """Extracted content structure from the video."""
    scene_length: str = Field(description="Scene length ‚Äì Fast cuts or long takes?")
    hook_type: str = Field(description="Hook type ‚Äì What happens in the first 3 seconds? (Question, Shock, Curiosity, Statement, Visual stimulus)")
    visual_frequency: str = Field(description="Visual frequency ‚Äì How often do visual elements change?")
    unique_visual_elements: str = Field(description="Unique visual elements ‚Äì What makes this content stand out visually?")


class VideoAnalysisSchema(BaseModel):
    """Output schema for the Video Analyst Agent."""
    schema_extraction: SchemaExtraction = Field(description="Extracted data structure of the content.")
    root_questions: List[str] = Field(description="Exactly 3 Root Questions targeting retention optimization.", min_length=3, max_length=3)


# ============================================================================
# Schema: Insight Extractor Agent
# ============================================================================
class AnalysisLevels(BaseModel):
    """The 4 analysis levels for each Root Question."""
    descriptive: str = Field(description="Descriptive: What was shown exactly?")
    diagnostic: str = Field(description="Diagnostic: Why does this moment captivate?")
    predictive: str = Field(description="Predictive: What retention rate is expected?")
    prescriptive: str = Field(description="Prescriptive: What change would maximize success?")


class FollowUpQuestion(BaseModel):
    """A follow-up question and its answer."""
    question: str = Field(description="The follow-up question.")
    answer: str = Field(description="The answer to the follow-up question.")


class RootQuestionAnalysis(BaseModel):
    """Complete analysis for a single Root Question."""
    root_question: str = Field(description="The Root Question being analyzed.")
    answer: str = Field(description="Direct answer to the Root Question.")
    follow_up_questions: List[FollowUpQuestion] = Field(description="4 Follow-up Questions with answers.", min_length=4, max_length=4)
    analysis_levels: AnalysisLevels = Field(description="Analysis across 4 levels.")


class StrategySchema(BaseModel):
    """Output schema for the Insight Extractor Agent."""
    most_engaging_element: str = Field(description="The single most engaging element identified.")
    hook_strategy: str = Field(description="How to stop the scroll in the first 3 seconds.")
    psychological_angle: str = Field(description="Why will people share this? (Humor, Shock, Relatability?)")
    root_question_analyses: List[RootQuestionAnalysis] = Field(description="Drill-down analysis for each Root Question.", min_length=3, max_length=3)
    prescriptive_summary: str = Field(description="Summary of all Prescriptive Insights.")


# ============================================================================
# Schema: Creator Agent
# ============================================================================
class HashtagStrategy(BaseModel):
    """A single strategic hashtag with its reasoning."""
    hashtag: str = Field(description="The hashtag (including #).")
    strategy: str = Field(description="Strategic reasoning for this hashtag.")


class CreatorOutputSchema(BaseModel):
    """Output schema for the Creator Agent."""
    caption: str = Field(description="The social media caption (max 280 characters).", max_length=280)
    hashtags: List[HashtagStrategy] = Field(description="5 strategic hashtags with reasoning.", min_length=5, max_length=5)


# ============================================================================
# Schema: Evaluator Agent
# ============================================================================
class EvaluationCriterion(BaseModel):
    """A single evaluation criterion with score and reasoning."""
    criterion: str = Field(description="Name of the criterion.")
    score: int = Field(description="Score for this criterion (1-10).", ge=1, le=10)
    reasoning: str = Field(description="Reasoning for the score.")


class EvaluationSchema(BaseModel):
    """Output schema for the Evaluator Agent."""
    overall_rating: int = Field(description="Overall rating from 1 to 10.", ge=1, le=10)
    criteria: List[EvaluationCriterion] = Field(
        description="Individual scores for: Factual Accuracy, Trend Relevance, Strategic Depth, Creative Originality, Anti-Hallucination.",
        min_length=5,
        max_length=5,
    )
    justification: str = Field(description="Detailed justification for the overall rating.")
    approved: bool = Field(description="True if score >= 7 (APPROVED), False if < 7 (NEEDS_REVISION).")
    feedback: Optional[str] = Field(default=None, description="Concrete improvement suggestions if NEEDS_REVISION.")
</file>

<file path="root_agent/subagents/__init__.py">
"""
Subagents package for the InsightBench Multi-Agent System.
"""

from .video_analyst_agent import video_analyst_agent
from .insight_extractor_agent import insight_extractor_agent
from .creator_agent import creator_agent
from .evaluator_agent import evaluator_agent
from .creation_evaluation_loop import creation_evaluation_loop

__all__ = [
    "video_analyst_agent",
    "insight_extractor_agent",
    "creator_agent",
    "evaluator_agent",
    "creation_evaluation_loop",
]
</file>

<file path="root_agent/subagents/creation_evaluation_loop.py">
"""
Sub-Agent: Creation-Evaluation Loop
LoopAgent wrapping Creator + Evaluator for retry logic (max 3 iterations).
"""

from google.adk.agents import LoopAgent
from root_agent.subagents.creator_agent import creator_agent
from root_agent.subagents.evaluator_agent import evaluator_agent


creation_evaluation_loop = LoopAgent(
    name="creation_evaluation_loop",
    description="Iteratively creates content and evaluates it. Loops until the Evaluator approves (calls exit_loop) or max iterations are reached.",
    sub_agents=[creator_agent, evaluator_agent],
    max_iterations=3,
)
</file>

<file path="root_agent/subagents/creator_agent.py">
"""
Sub-Agent: Creator
Generates social media captions and strategy using trend research.
"""

from google.adk.agents import Agent
from google.adk.tools import google_search


creator_agent = Agent(
    model="gemini-2.5-pro",
    name="creator_agent",
    description="Generates social media captions and strategy.",
    instruction="""
<context>
You are a specialized Social Media Content Creator AI. You receive structured data from a Video Analyst.
Your world is defined by viral trends, engagement metrics, and platform algorithms.
You have access to Google Search for real-time trend research.

**Input:**
- Insights from the Insight Extractor: {insights}
- If this is a revision round, check the conversation history for the Evaluator's feedback and incorporate it.
</context>

<objective>
Transform analytical data into a high-engagement social media post. Your goal is to maximize
"Stop Ratio" (Hook) and "Engagement" (Comments/Shares) by leveraging trends and expert knowledge.
</objective>

<mode>
Role: Gen-Z Social Media Manager & Growth Hacker.
Expertise: Copywriting, Hashtag Strategy, Viral Psychology.
</mode>

<people_of_interest>
The Audience: Short-form video consumers (Gen Z / Millennials). They have minimal attention spans.
The Client: A content creator who wants growth, not excuses.
</people_of_interest>

<attitude>
Tone: Authentic, relatable, trend-aware.
Behavior: Proactive (searching for trends), Creative (writing hooks), and Strategic (picking times).
NO "Corporate AI" speak (e.g., "Unlock your potential"). Use slang naturally.
</attitude>

<smart_goal>
   **Goal (Execution):**
   *   **S (Specific):** Create a caption + hashtags that directly address the identified insight.
   *   **M (Measurable):** < 280 characters (for short-form), > 3 hashtags.
   *   **A (Achievable):** Use copywriting best practices.
   *   **R (Relevant):** Translate the analysis into actionable content.
   *   **T (Time-bound):** Immediate generation after receiving insights.
</smart_goal>

<question_protocol>
   *   **Start:** "How do I package this insight emotionally?"
   *   **End:** "Would I share this myself?"
</question_protocol>

<specifications>
1. **Tool Usage (Trend Research):** You MUST call `google_search` to find *current* viral trends (e.g., "trending tiktok sounds [niche]").
2. **Drafting Process:** Combine Input Data + Google Trends to write the Hook and Caption.
3. **Constraint:** Do not invent details not in the input. Stay grounded in the video's reality.
4. **Chain of Thought:** Think inside <thinking_process> before producing the final output.
5. **NO URLS:** NEVER include URLs, hyperlinks, or source links in your output. Only mention trend names, not links.
</specifications>

<output_format>
## Trend Research
List each trend you found via Google Search (NO URLs or links!):
- Trend: [What you found ‚Äì name only, no URL]
- Trend: [What you found ‚Äì name only, no URL]

## Caption
[Your Caption here ‚Äì max 280 characters]

## Strategic Hashtags
1. #[Hashtag] ‚Äì Strategy: [Why this hashtag] ‚Äì
2. #[Hashtag] ‚Äì Strategy: [Why this hashtag] ‚Äì 
3. #[Hashtag] ‚Äì Strategy: [Why this hashtag] ‚Äì
4. #[Hashtag] ‚Äì Strategy: [Why this hashtag] ‚Äì 
5. #[Hashtag] ‚Äì Strategy: [Why this hashtag] ‚Äì 

## Strategic Justification
[Why this caption and hashtags embody the logic ‚Äì reference your trend research above]
</output_format>
""",
    tools=[google_search],
    output_key="creative_output",
)
</file>

<file path="root_agent/subagents/evaluator_agent.py">
"""
Sub-Agent: Evaluator
Validates content for facts, trends, and safety. Scores 1-10 (LLaMA-3-Eval Protocol).
"""

from google.adk.agents import Agent
from google.adk.tools import google_search
from root_agent.tools.exit_loop import exit_loop


evaluator_agent = Agent(
    model="gemini-2.0-flash",
    name="evaluator_agent",
    description="Validates content for facts, trends, and safety. Scores 1-10.",
    instruction="""
<context>
You are a STRICT Quality Assurance Auditor and Devil's Advocate. Your default stance is SKEPTICAL.
You assume the content is FLAWED until proven otherwise. You receive Draft Content from the Creator Agent.

**Your Mindset:** You are protecting a brand's reputation. One bad post can cause irreversible damage.
Your job is to FIND problems, not to confirm quality. If you cannot find a clear problem, look harder.

**Input:**
- Original Video Analysis (Ground Truth): {video_analysis}
- Generated Insights: {insights}
- Creative Output (Caption & Hashtags): {creative_output}
</context>

<objective>
DECONSTRUCT the content. Compare every word in the caption against the Ground Truth (video_analysis).
If the Creator added ANYTHING not present in the original analysis, that is a hallucination ‚Üí automatic fail.
You MUST use `google_search` to verify at least 2 claims before making any rating decision.
</objective>

<mandatory_verification>
**BEFORE you assign any score, you MUST complete these steps:**
1. Call `google_search` to verify the PRIMARY claim or topic in the caption.
2. Call `google_search` to verify at least ONE hashtag is currently trending (not outdated).
3. Compare the caption word-by-word against {video_analysis} ‚Äì flag any detail not in the original.
If you skip any of these steps, your evaluation is INVALID.
**IMPORTANT: NEVER include URLs, hyperlinks, or source links in your output. Only reference findings by name.**
</mandatory_verification>

<red_flags>
**Automatic score < 7 if ANY of these are detected:**
- Caption mentions facts, stats, or details NOT present in {video_analysis} ‚Üí HALLUCINATION
- Hashtags that are generic (#fyp, #viral) without niche-specific tags ‚Üí LAZY
- Caption is vague or could apply to any video ‚Üí NOT SPECIFIC ENOUGH
- Caption exceeds 280 characters ‚Üí FORMAT VIOLATION
- Fewer than 5 hashtags with strategic reasoning ‚Üí INCOMPLETE
- Caption uses "Corporate AI" language ("Unlock", "Elevate", "Journey") ‚Üí TONE VIOLATION
- Trends referenced are older than 30 days based on google_search results ‚Üí OUTDATED
</red_flags>

<rating_scale>
**Default starting score: 5 (mediocre). The Creator must EARN points above 5.**
- **10**: Every fact verified, trending hashtags confirmed via search, creative angle is unique. RARE.
- **8-9**: Strong content with minor phrasing improvements possible.
- **7**: Minimum acceptable. All facts check out but lacks creative spark.
- **5-6**: Mediocre. Generic content, unverified claims, or weak hashtag strategy.
- **3-4**: Poor. Contains hallucinations or factual errors.
- **1-2**: Completely wrong. Major misinformation or off-topic.

**IMPORTANT: A score of 7+ should be the EXCEPTION, not the default.**
Most first drafts deserve a 4-6. Be honest, not kind.
</rating_scale>

<smart_goal>
   **Goal (Quality Assurance):**
   *   **S (Specific):** Validate facts and trend relevance via Google Search.
   *   **M (Measurable):** 100% fact-check rate for all claimed facts.
   *   **A (Achievable):** Use external sources for verification.
   *   **R (Relevant):** Protects against "hallucinations" and outdated trends.
   *   **T (Time-bound):** Complete check before finalization.
</smart_goal>

<critical_stage_transition>
**TOOL USAGE RULES:**
- If score >= 7: Call the `exit_loop` tool to finalize. Do NOT just say "Approved" ‚Äì you MUST call the tool.
- If score < 7: Do NOT call `exit_loop`. Provide SPECIFIC, ACTIONABLE feedback:
  * Quote the exact problematic text from the caption.
  * State what is wrong (hallucination / outdated / generic / etc.).
  * Suggest a concrete replacement or fix.
</critical_stage_transition>

<output_format>
## Evaluation (LLaMA-3-Eval Protocol)

### Google Search Verification:
- Claim checked: "[exact claim]" ‚Üí Result: [TRUE/FALSE/UNVERIFIABLE]
- Hashtag checked: "#[hashtag]" ‚Üí Result: [TRENDING/OUTDATED/NOT FOUND]
(Do NOT include any URLs or links in this section)

### Rating: [X]/10

### Evaluation Criteria:
- **Factual Accuracy (Ground Truth):** [Score]/10 ‚Äì [Quote from caption vs. what video_analysis says]
- **Trend Relevance:** [Score]/10 ‚Äì 
- **Strategic Depth:** [Score]/10 ‚Äì [Is the insight specific or generic?]
- **Creative Originality:** [Score]/10 ‚Äì [Would this stop a scroll? Why/why not?]
- **Anti-Hallucination:** [Score]/10 ‚Äì [Any detail NOT in video_analysis?]

### Justification:
[Detailed justification with specific evidence ]

### STATUS: [APPROVED / NEEDS_REVISION]
[If NEEDS_REVISION: Quote the exact problem ‚Üí Explain why ‚Üí Suggest specific fix]
</output_format>
""",
    tools=[google_search, exit_loop],
    output_key="evaluation_result",
)
</file>

<file path="root_agent/subagents/insight_extractor_agent.py">
"""
Sub-Agent: Insight Extractor
Synthesizes analysis into a content strategy via multi-step drill-down.
"""

from google.adk.agents import Agent
from root_agent.output_structure import StrategySchema


insight_extractor_agent = Agent(
    model="gemini-2.0-flash",
    name="insight_extractor_agent",
    description="Synthesizes analysis into a content strategy via multi-step drill-down.",
    instruction="""
<context>
You are the Strategist. You sit between the Analyst (Video Data) and the Creator (Content).
You receive:
1. Video Analysis from the previous agent: {video_analysis}
</context>

<objective>
Synthesize the video analysis into a cohesive Content Strategy.
DO NOT write the caption yourself. Define the *angle* and strategy.
</objective>

<steps>
1. Identify the single `most_engaging_element` from the video data.
2. Define `hook_strategy`: How to stop the scroll in the first 3 seconds.
3. Define `psychological_angle`: Why will people share this? (Humor, Shock, Relatability?)
4. For each of the 3 Root Questions from the video analysis, perform a **Drill-Down**:
   - Answer the root question directly.
   - Generate exactly 4 follow-up questions with answers.
   - Analyze across 4 levels:
     * **Descriptive**: What was shown exactly?
     * **Diagnostic**: Why does this moment captivate?
     * **Predictive**: What retention rate is expected?
     * **Prescriptive**: What concrete change would maximize success?
5. Write a `prescriptive_summary` combining all prescriptive insights.
</steps>

You MUST respond with valid JSON matching the output schema. Do NOT include any text outside the JSON.
""",
    output_key="insights",
    output_schema=StrategySchema,
    disallow_transfer_to_parent=True,
    disallow_transfer_to_peers=True,
)
</file>

<file path="root_agent/subagents/video_analyst_agent.py">
"""
Sub-Agent: Video Analyst
Extracts the data structure of social media content and formulates Root Questions.
"""

from google.adk.agents import Agent
from root_agent.output_structure import VideoAnalysisSchema


video_analyst_agent = Agent(
    model="gemini-2.0-flash",
    name="video_analyst_agent",
    description="Extracts the data structure of social media content and formulates Root Questions for retention optimization.",
    instruction="""
<context>
You are an advanced Computer Vision and Audio Analysis AI Agent in a multi-agent system.
Your task is to transform video input (or descriptions) into structured data that serves as
a "Schema" for subsequent analyses.
Goal: Identify patterns that favor a drop-off rate below 20% (SMART goal).
</context>

<role>
Senior Computer Vision Engineer & Data Annotator.
Focus: Object detection, OCR, sentiment analysis, and audio classification.
Attitude: Clinical, objective, precise ‚Äì you describe observable reality without artistic interpretation.
</role>

<specifications>
1. **Hook Focus (SMART Goal):** Analysis of the first 3 seconds is your highest priority.
2. **Schema Extraction:** For `schema_extraction`, fill in:
   - `scene_length`: Fast cuts or long takes?
   - `hook_type`: What happens in the first 3 seconds? (Question, Shock, Curiosity, Statement, Visual stimulus)
   - `visual_frequency`: How often do visual elements change?
   - `unique_visual_elements`: What makes this content stand out visually?
3. **Root Questions:** Formulate exactly 3 Root Questions targeting retention optimization:
   - Question 1: Why does this content succeed or fail?
   - Question 2: What potential trends does this relate to?
   - Question 3: How can this be optimized?
4. **Clinical Style:** No human conversation, only structured data output.
5. **Precision:** Your data extraction must be detailed enough to outperform any standard agent.
</specifications>

You MUST respond with valid JSON matching the output schema. Do NOT include any text outside the JSON.
""",
    output_key="video_analysis",
    output_schema=VideoAnalysisSchema,
    disallow_transfer_to_parent=True,
    disallow_transfer_to_peers=True,
)
</file>

<file path="root_agent/tools/__init__.py">
"""
Tools package for the InsightBench Multi-Agent System.
"""

from .exit_loop import exit_loop
from .engagement import calculate_engagement

__all__ = ["exit_loop", "calculate_engagement"]
</file>

<file path="root_agent/tools/engagement.py">
"""
Tool: calculate_engagement
Calculates a weighted engagement rate and provides a qualitative assessment.
"""

from typing import Dict, Any


def calculate_engagement(likes: int, comments: int, shares: int, saves: int, reach: int) -> Dict[str, Any]:
    """
    Calculates a weighted engagement rate and provides a qualitative assessment.

    Formula: ((Likes * 1) + (Comments * 2) + (Shares * 3) + (Saves * 3)) / Reach * 100

    Args:
        likes: Number of likes.
        comments: Number of comments.
        shares: Number of shares.
        saves: Number of saves.
        reach: Total reach or unique views.

    Returns:
        dict: A dictionary containing the numeric 'rate', a string 'assessment', and 'details'.
    """
    if reach == 0:
        return {
            "rate": 0.0,
            "assessment": "Error (Zero Reach)",
            "details": "Reach cannot be zero."
        }

    weighted_interactions = (likes * 1) + (comments * 2) + (shares * 3) + (saves * 3)
    score = (weighted_interactions / reach) * 100

    assessment = "Needs Optimization"
    if score > 10:
        assessment = "Viral Potential! üî•"
    elif score > 5:
        assessment = "Good Performance üëç"

    return {
        "rate": round(score, 2),
        "assessment": assessment,
        "details": f"Weighted Score: {score:.2f}% (Likes: {likes}, Comments: {comments}, Shares: {shares}, Saves: {saves})"
    }
</file>

<file path="root_agent/tools/exit_loop.py">
"""
Tool: exit_loop
Exits the Creator-Evaluator LoopAgent when content is approved (score >= 7).
"""


def exit_loop(tool_context) -> dict:
    """Call this function ONLY when you APPROVE the content (score >= 7).
    This will exit the creation-evaluation loop and finalize the process."""
    tool_context.actions.escalate = True
    return {"status": "Loop exited. Content approved and finalized."}
</file>

<file path=".gitignore">
# Python-generated files
__pycache__/
*.py[oc]
build/
dist/
wheels/
*.egg-info
.env
# Virtual environments
.venv
</file>

<file path=".python-version">
3.12
</file>

<file path="pyproject.toml">
[project]
name = "test-abgabe"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.12"
dependencies = [
    "adk>=0.0.5",
    "google>=3.0.0",
    "google-adk[eval]==1.16.0",
    "google-genai>=1.57.0",
    "google-generativeai>=0.8.6",
    "pydantic>=2.12.5",
    "python-dotenv>=1.2.1",
    "streamlit>=1.52.2",
]
</file>

<file path="README.md">
# üöÄ InsightBench: Social Media Analyse & Erstellungs-Architektur (Final)

Basierend auf "INSIGHTBENCH: EVALUATING BUSINESS ANALYTICS AGENTS THROUGH MULTI-STEP INSIGHT GENERATION".

## 1. Projekt√ºbersicht

Ein Multi-Agenten-System, das darauf ausgelegt ist, Social-Media-Inhalte zu optimieren, indem tiefe Einblicke (Insights) anstatt nur oberfl√§chlicher Daten generiert werden. Das System nutzt eine Pipeline von **Deskriptiver**, **Diagnostischer**, **Pr√§diktiver** und **Pr√§skriptiver** Analytik.

## 2. Die "InsightBench" Agenten-Pipeline

### Schritt 1: Video Analyst Agent (Der Beobachter)

- **Modell**: `gemini-2.0-flash`
- **Rolle**: Extraktion der Datenstruktur (Schema).
- **Kernaufgabe**: Erfasst nicht nur visuelle Eindr√ºcke, sondern extrahiert statistische Eckpunkte: Einzigartige visuelle Elemente, Szenenl√§ngen und die Verteilung der ersten 3 Sekunden (Hook).
- **Output**: Formulierung von **3 Root Questions** (Kernfragen), die speziell auf die Retentions-Logik abzielen.

### Schritt 2: Insight Extractor Agent (Der Analyst)

- **Modell**: `gemini-2.0-flash`
- **Rolle**: Durchf√ºhrung einer **Multi-Step-Analyse** zur Vermeidung oberfl√§chlicher Ergebnisse.
- **Mechanismus (Drill-Down)**: Zu jeder beantworteten Root Question generiert dieser Agent automatisch **n Follow-up Fragen**, um tieferliegende Muster zu finden. **Hinweis:** Dieser Agent arbeitet jetzt rein basierend auf der Video-Analyse, ohne externe Trend-Daten (TrendScout entfernt).
- **Analyse-Level**:
  - _Deskriptiv_: Was passiert im Video?
  - _Diagnostisch_: Warum funktioniert der Hook?
  - _Pr√§diktiv_: Was wird passieren (Viralit√§t)?
  - _Pr√§skriptiv_: Welche konkreten Handlungsempfehlungen gibt es?

### Schritt 3: Creator Agent (Der K√ºnstler)

- **Modell**: `gemini-2.5-pro` (Maximale kreative Tiefe)
- **Rolle**: Synthetisierung der **Pr√§skriptiven Insights** in Captions und Hashtags.
- **Anforderung**: √úbersetzung der strategischen Winkel in emotionalen Content, der genau auf den identifizierten Insight eingeht.

### Schritt 4: Evaluator Agent (Der numerische Richter)

- **Modell**: `gemini-1.5-flash` + **Google Search**
- **Rolle**: Qualit√§tssicherung durch das **LLaMA-3-Eval Protokoll**.
- **Numerisches Rating (Anti-Halluzination)**: Der Agent vergibt ein **Rating von 1-10** basierend auf der N√§he des Entwurfs zum Video-Inhalt (Ground Truth).
  - **10**: Faktisch perfekt und trend-aktuell.
  - **< 7**: Signal zur √úberarbeitung (Loop), falls Halluzinationen oder Abweichungen erkannt werden.
- **Validierung**: Nutzung von Google Search zur Verifizierung von Fakten und Trend-Aktualit√§t.

## 3. Erfolgskennzahlen (S.M.A.R.T.)

1.  **Insight-Tiefe**: Mindestens 1 valider Punkt pro Analyse-Kategorie.
2.  **Pr√§zision**: LLaMA-3-Eval Score von durchschnittlich > 8.0 f√ºr freigegebene Posts.
3.  **Effizienz**: Abschluss der Analysezyklen ohne unn√∂tiges Overengineering durch stabilisierte Prompts (Temperatur 0.0).

---
</file>

<file path="root_agent/__init__.py">
from . import agent
</file>

<file path="root_agent/.gitignore">
# Python-generated files
__pycache__/
*.py[oc]
build/
dist/
wheels/
*.egg-info
.env
# Virtual environments
.venv
</file>

<file path="root_agent/test/msg.py">
import sys
import os
import asyncio
import json
from google.genai import types
from dotenv import load_dotenv
import sys

# Windows Fix: Force UTF-8 output
if sys.platform == "win32":
    sys.stdout.reconfigure(encoding='utf-8')

load_dotenv()

# 1. Pfad Setup: 2 Ebenen hoch gehen (../../)
root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../'))
sys.path.append(root_dir)

# 2. Importiere deinen ECHTEN Runner
try:
    from root_agent.agent import root_agent
    from google.adk import Runner
    from google.adk.sessions import InMemorySessionService
    from google.adk.apps import App
    
    # Wrap agent in App
    app = App(root_agent=root_agent, name="social_media_analytics_app")

    # Instantiate the runner with the app and session service
    runner = Runner(app=app, session_service=InMemorySessionService())
    print("[OK] Modul 'root_agent' erfolgreich geladen.")
except ImportError as e:
    print(f"[FAIL] FEHLER: Konnte 'root_agent' nicht importieren. Pfad: {root_dir}")
    print(f"Detail: {e}")
    sys.exit(1)

async def run_single_test(test_case):
    """F√ºhrt einen einzelnen Testfall aus."""
    user_input = test_case['user_input']
    print(f"\n[TEST] Test: {test_case['test_case_id']}")
    print(f"   Input: '{user_input}'")

    # --- WICHTIGE KORREKTUR HIER ---
    # Wir lesen den korrekten App-Namen direkt aus dem Runner aus.
    # In deiner agent.py ist das "root_agent".
    correct_app_name = getattr(runner, "app_name", "root_agent")

    # Session starten mit dem KORREKTEN App-Namen
    session = await runner.session_service.create_session(
        user_id='eval_bot', 
        app_name=correct_app_name
    )

    parts = [types.Part(text=user_input)]
    
    # Check for video file
    video_file = test_case.get('video_file')
    if video_file:
        video_path = os.path.join(os.path.dirname(__file__), video_file)
        # Fallback: check root dir if not found in test dir
        if not os.path.exists(video_path):
             video_path = os.path.join(root_dir, video_file)
             
        if os.path.exists(video_path):
            print(f"   [INFO] Loading video: {video_file}")
            try:
                with open(video_path, "rb") as f:
                    video_data = f.read()
                parts.append(types.Part.from_bytes(data=video_data, mime_type="video/mp4"))
            except Exception as e:
                print(f"   [FAIL] Could not load video: {e}")
        else:
            print(f"   [WARN] Video file not found: {video_file}")

    content = types.Content(role='user', parts=parts)

    # Agent ausf√ºhren
    print("   [WAIT] Agent arbeitet (Google Search )...")
    try:
        events = runner.run_async(
            user_id='eval_bot',
            session_id=session.id,
            new_message=content
        )
    except Exception as e:
        print(f"   [FAIL] START-FEHLER: {e}")
        return False

    all_texts = []  # Sammle ALLE Text-Parts aus ALLEN Events
    
    # Antwort Stream verarbeiten
    try:
        async for event in events:
            # Agent-Name loggen (falls vorhanden)
            agent_name = getattr(event, 'author', '')
            if event.content and event.content.parts:
                for part in event.content.parts:
                    text = part.text
                    if text:
                        # Prefix mit Agent-Name fuer bessere Zuordnung
                        if agent_name:
                            all_texts.append(f"[{agent_name}]: {text}")
                        else:
                            all_texts.append(text)
    except Exception as e:
        print(f"   [FAIL] CRITICAL ERROR w√§hrend der Ausf√ºhrung: {e}")
        return False

    # Alles zusammenfuegen
    final_text = "\n".join(all_texts)
    
    if not final_text.strip():
        print("   [WARN] Warnung: Keine Textantwort erhalten.")
    
    # √úberpr√ºfung (Simple String Matching)
    expected_keywords = test_case.get('expected_output_contains', [])
    passed = True
    missing = []

    for keyword in expected_keywords:
        if keyword.lower() not in final_text.lower():
            passed = False
            missing.append(keyword)

    # Ergebnis Ausgabe
    print(f"   [INFO] Antwort-Vorschau: {final_text.replace(chr(10), ' ')[:300]}...")
    
    if passed:
        print("   [OK] STATUS: PASS")
    else:
        print("   [FAIL] STATUS: FAIL")
        print(f"      Fehlende Keywords: {missing}")

    return passed

async def main():
    print("[START] Starte Manuellen Evaluierungs-Loop (Direct Runner Mode)")
    print("---------------------------------------------------------")
    
    # Lade die Testf√§lle
    # Lade die Testf√§lle
    json_path = os.path.join(os.path.dirname(__file__), "scenarios_debug.json")
    if not os.path.exists(json_path):
        json_path = os.path.join(os.path.dirname(__file__), "scenarios_test.json")
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            test_cases = json.load(f)
            print(f"[INFO] Loaded scenarios from: {os.path.basename(json_path)}")
    except FileNotFoundError:
        print(f"[FAIL] Konnte Testdatei nicht finden: {json_path}")
        return

    # Loop durch alle Tests
    passed_count = 0
    for case in test_cases:
        if await run_single_test(case):
            passed_count += 1
            
    print("\n=========================================================")
    print(f"[RESULT] GESAMTERGEBNIS: {passed_count}/{len(test_cases)} Tests bestanden.")
    print("=========================================================")

if __name__ == "__main__":
    asyncio.run(main())
</file>

<file path="root_agent/test/testmsg.py">
import sys
import os
import asyncio
import json
from google.genai import types

# 1. Pfad Setup: 2 Ebenen hoch gehen (../../)
root_dir = os.path.abspath(os.path.join(os.path.dirname(__file__), '../../'))
sys.path.append(root_dir)

# 2. Importiere deinen ECHTEN Runner
try:
    from projekt_bosch.agent import runner
    print("‚úÖ Modul 'projekt_bosch.agent' erfolgreich geladen.")
except ImportError as e:
    print(f"‚ùå FEHLER: Konnte 'projekt_bosch' nicht importieren. Pfad: {root_dir}")
    print(f"Detail: {e}")
    sys.exit(1)

async def run_single_test(test_case):
    """F√ºhrt einen einzelnen Testfall aus."""
    user_input = test_case['user_input']
    print(f"\nüîπ Test: {test_case['test_case_id']}")
    print(f"   Input: '{user_input}'")

    # --- WICHTIGE KORREKTUR HIER ---
    # Wir lesen den korrekten App-Namen direkt aus dem Runner aus.
    # In deiner agent.py ist das "root_agent".
    correct_app_name = getattr(runner, "app_name", "root_agent")

    # Session starten mit dem KORREKTEN App-Namen
    session = await runner.session_service.create_session(
        user_id='eval_bot', 
        app_name=correct_app_name
    )

    content = types.Content(role='user', parts=[types.Part(text=user_input)])

    # Agent ausf√ºhren
    print("   ‚è≥ Agent arbeitet (Google Search & DB)...")
    try:
        events = runner.run_async(
            user_id='eval_bot',
            session_id=session.id,
            new_message=content
        )
    except Exception as e:
        print(f"   ‚ùå START-FEHLER: {e}")
        return False

    final_text = ""
    found_text = False
    
    # Antwort Stream verarbeiten
    try:
        async for event in events:
            if event.content and event.content.parts:
                for part in event.content.parts:
                    text = part.text
                    # Filterung: Wir wollen nur den finalen Markdown-Text, kein JSON
                    if text and not text.strip().startswith("{") and "search_metadata" not in text:
                        final_text = text
                        found_text = True
    except Exception as e:
        print(f"   ‚ùå CRITICAL ERROR w√§hrend der Ausf√ºhrung: {e}")
        return False

    if not found_text:
        print("   ‚ö†Ô∏è  Warnung: Keine saubere Textantwort erhalten (nur JSON/Trace?).")
        # Optional: Gib den letzten Stand aus, falls vorhanden
        if final_text:
            print(f"   (Letzter Stand: {final_text[:300]}...)")
    
    # √úberpr√ºfung (Simple String Matching)
    expected_keywords = test_case.get('expected_output_contains', [])
    passed = True
    missing = []

    for keyword in expected_keywords:
        if keyword.lower() not in final_text.lower():
            passed = False
            missing.append(keyword)

    # Ergebnis Ausgabe
    print(f"   üìù Antwort-Vorschau: {final_text.replace(chr(10), ' ')[:300]}...")
    
    if passed:
        print("   ‚úÖ STATUS: PASS")
    else:
        print("   ‚ùå STATUS: FAIL")
        print(f"      Fehlende Keywords: {missing}")

    return passed

async def main():
    print("üöÄ Starte Manuellen Evaluierungs-Loop (Direct Runner Mode)")
    print("---------------------------------------------------------")
    
    # Lade die Testf√§lle
    json_path = os.path.join(os.path.dirname(__file__), "scenarios_test.json")
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            test_cases = json.load(f)
    except FileNotFoundError:
        print(f"‚ùå Konnte Testdatei nicht finden: {json_path}")
        return

    # Loop durch alle Tests
    passed_count = 0
    for case in test_cases:
        if await run_single_test(case):
            passed_count += 1
            
    print("\n=========================================================")
    print(f"üìä GESAMTERGEBNIS: {passed_count}/{len(test_cases)} Tests bestanden.")
    print("=========================================================")

if __name__ == "__main__":
    asyncio.run(main())
</file>

<file path="test_output.txt">
C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\google\cloud\aiplatform\models.py:52: FutureWarning: Support for google-cloud-storage < 3.0.0 will be removed in a future version of google-cloud-aiplatform. Please upgrade to google-cloud-storage >= 3.0.0.
  from google.cloud.aiplatform.utils import gcs_utils
C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\root_agent\test\msg.py:27: UserWarning: [EXPERIMENTAL] App: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.
  app = App(root_agent=root_agent, name="social_media_analytics_app")
[OK] Modul 'root_agent' erfolgreich geladen.
[START] Starte Manuellen Evaluierungs-Loop (Direct Runner Mode)
---------------------------------------------------------
[INFO] Loaded scenarios from: scen[OK] Modul 'root_agent' erfolgreich geladen.
[START] Starte Manuellen Evaluierungs-Loop (Direct Runner Mode)
---------------------------------------------------------

[TEST] Test: TC01_TIKTOK_COOKING_HOOK
   Input: 'Analyze this video: A fast-paced 15-second TikTok showing a quick pizza recipe. The first 3 seconds show melting cheese pulling apart (visual stimulus). The chef cuts the pizza rapidly. Background audio is upbeat lo-fi. The video ends with a 'Subscribe for more' text overlay.'
   [WAIT] Agent arbeitet (Google Search )...
   [INFO] Antwort-Vorschau: Acknowledged. The content has been approved. I will incorporate the feedback regarding creative additions and aim for higher originality in the next iteration. Ready for the next task....
   [FAIL] STATUS: FAIL
      Fehlende Keywords: ['Video Analyst', 'Visual stimulus', 'Creator Agent', '#pizza', 'Status: Loop exited']

[TEST] Test: TC02_TECH_REVIEW_RETENTION
   Input: 'Analyze this video: A 60-second YouTube Short reviewing the new iPhone 16. The host starts by dropping the phone (Shock hook). He talks about the new camera sensor. The middle section is static talking head. Retention usually drops there.'
   [WAIT] Agent arbeitet (Google Search )...
   [INFO] Antwort-Vorschau: Understood. Process finalized. Standing by for the next project....
   [FAIL] STATUS: FAIL
      Fehlende Keywords: ['Shock', 'Insight Extractor', 'Prescriptive', 'Evaluator Agent', 'APPROVED']

[TEST] Test: TC03_TRAVEL_VLOG_MISSING_DETAILS
   Input: 'Analyze this video: A travel vlog about Bali. It shows beaches and rice terraces.'
   [WAIT] Agent arbeitet (Google Search )...
   [FAIL] CRITICAL ERROR w√§hrend der Ausf√ºhrung: 503 UNAVAILABLE. {'error': {'code': 503, 'message': 'This model is currently experiencing high demand. Spikes in demand are usually temporary. Please try again later.', 'status': 'UNAVAILABLE'}}

[TEST] Test: TC04_CREATOR_COMEDY_SKIT
   Input: 'Analyze this video: A short comedy skit about 'Working from Home'. The person is wearing a suit jacket but pajama pants (Visual Gag). They mute the zoom call to scream into a pillow. The hook is the ringtone sound.'
   [WAIT] Agent arbeitet (Google Search )...
   [INFO] Antwort-Vorschau: ## Trend Research - Trend: Relatable work-from-home humor, specifically the "professional from the waist up" gag, is an established and consistently viral theme. - Trend: Memes and short videos that capture the shared struggles of remote work, such as burnout and distractions, continue to see high e...
   [FAIL] STATUS: FAIL
      Fehlende Keywords: ['Creator Agent']

[TEST] Test: TC05_PENGUIN_VIDEO_ANALYSIS
   Input: 'Analyze this video file. What animals are shown and what are they doing?'
   [INFO] Loading video: penguin.mp4
   [WAIT] Agent arbeitet (Google Search )...
   [INFO] Antwort-Vorschau: Excellent. The content is approved and ready for posting....
   [FAIL] STATUS: FAIL
      Fehlende Keywords: ['Penguin', 'Schema', 'Strategy']

=========================================================
[RESULT] GESAMTERGEBNIS: 0/5 Tests bestanden.
=========================================================
 line 395, in _run_async_impl
    async for event in agen:
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\google\adk\flows\llm_flows\base_llm_flow.py", line 356, in run_async
    async for event in agen:
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\google\adk\flows\llm_flows\base_llm_flow.py", line 414, in _run_one_step_async
    async for llm_response in agen:
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\google\adk\flows\llm_flows\base_llm_flow.py", line 780, in _call_llm_async
    async for event in agen:
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\google\adk\flows\llm_flows\base_llm_flow.py", line 764, in _call_llm_with_tracing
    async for llm_response in agen:
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\google\adk\flows\llm_flows\base_llm_flow.py", line 958, in _run_and_handle_error
    async for response in agen:
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\google\adk\models\google_llm.py", line 171, in generate_content_async
    response = await self.api_client.aio.models.generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\google\genai\models.py", line 7331, in generate_content
    response = await self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\google\genai\models.py", line 6095, in _generate_content
    response = await self._api_client.async_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\google\genai\_api_client.py", line 1442, in async_request
    result = await self._async_request(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\google\genai\_api_client.py", line 1375, in _async_request
    return await self._async_retry(  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 111, in __call__
    do = await self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 153, in iter
    result = await action(retry_state)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\tenacity\_utils.py", line 99, in inner
    return call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\tenacity\__init__.py", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marsv\AppData\Roaming\uv\python\cpython-3.12.11-windows-x86_64-none\Lib\concurrent\futures\_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marsv\AppData\Roaming\uv\python\cpython-3.12.11-windows-x86_64-none\Lib\concurrent\futures\_base.py", line 401, in __get_result
    raise self._exception
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\tenacity\asyncio\__init__.py", line 114, in __call__
    result = await fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\google\genai\_api_client.py", line 1312, in _async_request_once
    response = await self._aiohttp_session.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\aiohttp\client.py", line 779, in _request
    resp = await handler(req)
           ^^^^^^^^^^^^^^^^^^
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\aiohttp\client.py", line 757, in _connect_and_send_request
    await resp.start(conn)
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\aiohttp\client_reqrep.py", line 539, in start
    message, payload = await protocol.read()  # type: ignore[union-attr]
                       ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\.venv\Lib\site-packages\aiohttp\streams.py", line 703, in read
    await self._waiter
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\marsv\Desktop\UNI\Agentic_AI\test_abgabe\root_agent\test\msg.py", line 162, in <module>
    asyncio.run(main())
  File "C:\Users\marsv\AppData\Roaming\uv\python\cpython-3.12.11-windows-x86_64-none\Lib\asyncio\runners.py", line 195, in run
    return runner.run(main)
           ^^^^^^^^^^^^^^^^
  File "C:\Users\marsv\AppData\Roaming\uv\python\cpython-3.12.11-windows-x86_64-none\Lib\asyncio\runners.py", line 123, in run
    raise KeyboardInterrupt()
KeyboardInterrupt
</file>

<file path="root_agent/test/scenarios_test.json">
[
    {
        "test_case_id": "TC01_TIKTOK_COOKING_HOOK",
        "description": "Tests the Video Analyst's ability to extract schema from a cooking TikTok.",
        "comment": "Keywords match actual output_schema fields and agent behavior.",
        "user_input": "Analyze this video: A fast-paced 15-second TikTok showing a quick pizza recipe. The first 3 seconds show melting cheese pulling apart (visual stimulus). The chef cuts the pizza rapidly. Background audio is upbeat lo-fi. The video ends with a 'Subscribe for more' text overlay.",
        "expected_output_contains": [
            "hook",
            "scene_length",
            "caption",
            "hashtag"
        ]
    },
    {
        "test_case_id": "TC02_TECH_REVIEW_RETENTION",
        "description": "Tests the Insight Extractor's drill-down analysis for a tech review.",
        "comment": "Keywords match StrategySchema fields.",
        "user_input": "Analyze this video: A 60-second YouTube Short reviewing the new iPhone 16. The host starts by dropping the phone (Shock hook). He talks about the new camera sensor. The middle section is static talking head. Retention usually drops there.",
        "expected_output_contains": [
            "hook",
            "prescriptive",
            "retention",
            "caption"
        ]
    },
    {
        "test_case_id": "TC03_TRAVEL_VLOG_MISSING_DETAILS",
        "description": "Tests the Evaluator's ability to handle vague input.",
        "comment": "Keywords match EvaluationSchema fields.",
        "user_input": "Analyze this video: A travel vlog about Bali. It shows beaches and rice terraces.",
        "expected_output_contains": [
            "score",
            "caption",
            "hashtag",
            "hook"
        ]
    },
    {
        "test_case_id": "TC04_CREATOR_COMEDY_SKIT",
        "description": "Tests the Creator Agent's humor and trend integration.",
        "comment": "Validates that the Creator Agent picks up on the comedy aspect.",
        "user_input": "Analyze this video: A short comedy skit about 'Working from Home'. The person is wearing a suit jacket but pajama pants (Visual Gag). They mute the zoom call to scream into a pillow. The hook is the ringtone sound.",
        "expected_output_contains": [
            "caption",
            "hashtag",
            "hook",
            "score"
        ]
    }
]
</file>

<file path="app.py">
import streamlit as st
import os
import json
import re
import requests
import base64
from typing import Optional, Dict, Any
import uuid


def strip_urls(text: str) -> str:
    """Remove all URLs, hyperlinks, and markdown links from text."""
    # Remove markdown links [text](url) ‚Üí text
    text = re.sub(r'\[([^\]]*)\]\([^)]+\)', r'\1', text)
    # Remove raw URLs (http/https/www)
    text = re.sub(r'https?://\S+', '', text)
    text = re.sub(r'www\.\S+', '', text)
    # Clean up leftover whitespace
    text = re.sub(r'  +', ' ', text)
    return text.strip()

try:
    import sseclient
except ImportError:
    sseclient = None

# --- Constants ---
# ADK Web Server uses SSE streaming at /run_sse
ADK_BASE_URL = "http://localhost:8000"

# --- Page Configuration ---
st.set_page_config(
    page_title="Social Media AI Booster",
    page_icon="üöÄ",
    layout="wide",
    initial_sidebar_state="expanded",
)

# --- Custom CSS for Aesthetics ---
st.markdown("""
<style>
    .big-font {
        font-size:30px !important;
        font-weight: bold;
    }
    .stTabs [data-baseweb="tab-list"] {
        gap: 10px;
    }
    .stTabs [data-baseweb="tab"] {
        height: 50px;
        white-space: pre-wrap;
        border-radius: 4px 4px 0px 0px;
        gap: 1px;
        padding-top: 10px;
        padding-bottom: 10px;
    }
    .metric-card {
        background-color: #f0f2f6;
        padding: 20px;
        border-radius: 10px;
        margin-bottom: 10px;
    }
</style>
""", unsafe_allow_html=True)

# --- Sidebar: Configuration & Tools ---
with st.sidebar:
    # st.markdown("## ‚öôÔ∏è Configuration")
    
    # # API Configuration
    # api_url = st.text_input("ADK Server URL", value=DEFAULT_API_URL, help="The URL of your running 'adk api_server'")
    
    # st.markdown("---")
    
    # Story 5: Engagement Calculator Inputs
    st.markdown("## üìà Engagement Data")
    with st.expander("Input Stats", expanded=True):
        col_inp1, col_inp2 = st.columns(2)
        with col_inp1:
            likes = st.number_input("Likes", min_value=0, value=150)
            comments = st.number_input("Comments", min_value=0, value=45)
        with col_inp2:
            shares = st.number_input("Shares (3x)", min_value=0, value=10)
            saves = st.number_input("Saves (3x)", min_value=0, value=5)
            
        reach = st.number_input("Reach", min_value=1, value=1200)
        st.caption("Enter stats to let the agent calculate viral potential.")

# --- Main Area ---
st.title("üöÄ Social Media AI Booster")
st.markdown("### Transform your video into viral content with Multi-Agent AI.")

# File Uploader (Visual only for now, unless we send path/content)
# File Uploader
uploaded_file = st.file_uploader("Upload Video Content", type=['mp4', 'mov'])

if uploaded_file:
    # Story: File Details
    file_details = {
        "Filename": uploaded_file.name,
        "FileType": uploaded_file.type,
        "FileSize": f"{uploaded_file.size / (1024 * 1024):.2f} MB"
    }
    
    col1, col2, col3 = st.columns(3)
    col1.metric("Filename", file_details["Filename"])
    col2.metric("Size", file_details["FileSize"])
    col3.metric("Type", file_details["FileType"])
    
    st.divider()

# Helper to process SSE response stream
def process_sse_stream(response):
    """
    Parses the SSE stream from /run_sse endpoint.
    Collects all text parts from all events and returns the combined output.
    """
    all_texts = []
    last_author = ""
    
    for line in response.iter_lines(decode_unicode=True):
        if not line or not line.startswith("data: "):
            continue
        
        data_str = line[6:]  # Remove 'data: ' prefix
        if data_str.strip() == "[DONE]":
            break
            
        try:
            event = json.loads(data_str)
        except json.JSONDecodeError:
            continue
            
        # Extract author
        author = event.get("author", "")
        if author:
            last_author = author
            
        # Extract text from content.parts
        content = event.get("content", {})
        if not content:
            continue
        parts = content.get("parts", [])
        for part in parts:
            text = part.get("text", "")
            if text:
                all_texts.append({"author": last_author, "text": text})
    
    return all_texts


def build_structured_result(text_entries):
    """
    Groups SSE text entries by agent author.
    Returns a dict: { agent_name: combined_text, ... }
    This lets us display Creator output when Evaluator approved.
    """
    agent_outputs = {}
    
    for entry in text_entries:
        author = entry.get("author", "unknown")
        text = entry.get("text", "")
        if author not in agent_outputs:
            agent_outputs[author] = []
        agent_outputs[author].append(text)
    
    # Merge text per agent (keep last entry as the "final" output for that agent)
    result = {}
    for agent, texts in agent_outputs.items():
        # Try to parse all texts into JSON, keep last valid JSON as structured
        last_json = None
        for t in texts:
            try:
                parsed = json.loads(t.strip())
                if isinstance(parsed, dict):
                    last_json = parsed
            except (json.JSONDecodeError, AttributeError):
                pass
        
        result[agent] = {
            "full_text": "\n".join(texts),
            "structured": last_json
        }
    
    return result

# State Management
if "agent_result" not in st.session_state:
    st.session_state.agent_result = None

if uploaded_file:
    # Button to trigger agents
    if st.button("‚ú® Analyze & Boost", type="primary"):
        # Story 8: Spinner/Progress -> st.status
        with st.status("üöÄ Processing Video...", expanded=True) as status:
            
            try:
                # Prepare Payload
                status.write("üìù Preparing data payload...")
                if "session_id" not in st.session_state:
                    st.session_state.session_id = str(uuid.uuid4())
                
                settings_app_name = "root_agent" 
                settings_user_id = "user"
                
                # --- Create Session ---
                create_session_url = f"{ADK_BASE_URL}/apps/{settings_app_name}/users/{settings_user_id}/sessions"
                
                # Use a new session for each analysis
                session_id = str(uuid.uuid4())
                st.session_state.session_id = session_id
                
                status.write(f"üîß Creating session...")
                creation_payload = {"session_id": session_id}
                creation_response = requests.post(create_session_url, json=creation_payload, timeout=10)
                
                if creation_response.status_code not in [200, 201]:
                     status.warning(f"Session creation warning: {creation_response.status_code} - {creation_response.text}")
                else:
                     status.write("‚úÖ Session registered.")

                # --- Build message parts ---
                status.write(f"üì° Sending to {settings_app_name} via SSE streaming...")
                
                user_text = (
                    f"Analyze the video content of the uploaded file: {uploaded_file.name}. "
                    f"Engagement Stats provided by user: Likes={likes}, Comments={comments}, "
                    f"Shares={shares}, Saves={saves}, Reach={reach}."
                )
                
                message_parts = [{"text": user_text}]
                
                # Upload actual video bytes as inline_data
                uploaded_file.seek(0)
                video_bytes = uploaded_file.read()
                video_b64 = base64.b64encode(video_bytes).decode("utf-8")
                message_parts.append({
                    "inline_data": {
                        "mime_type": uploaded_file.type or "video/mp4",
                        "data": video_b64
                    }
                })

                # --- Use /run_sse endpoint (SSE streaming) ---
                adk_run_url = f"{ADK_BASE_URL}/run_sse"
                
                payload = {
                    "app_name": settings_app_name, 
                    "user_id": settings_user_id,
                    "session_id": session_id,
                    "new_message": {
                        "role": "user",
                        "parts": message_parts
                    }
                }
                
                status.write("‚è≥ Agent pipeline is running (this may take 1-2 minutes)...")
                response = requests.post(adk_run_url, json=payload, stream=True, timeout=300)
                
                if response.status_code == 200:
                    # Parse SSE stream
                    text_entries = process_sse_stream(response)
                    
                    if text_entries:
                        status.write(f"‚úÖ Received {len(text_entries)} responses from agents!")
                        result = build_structured_result(text_entries)
                        
                        # Also store raw entries for debug
                        st.session_state.agent_result = result
                        st.session_state.agent_raw = text_entries
                        
                        status.update(label="Analysis Complete!", state="complete", expanded=False)
                        st.toast("Analysis Complete!", icon="‚úÖ")
                    else:
                        status.update(label="No Response", state="error", expanded=True)
                        st.error("The agent pipeline returned no text output.")
                else:
                    status.update(label="API Error", state="error", expanded=True)
                    st.error(f"API Error: {response.status_code} - {response.text}")
                
            except requests.exceptions.ConnectionError:
                status.update(label="Connection Failed", state="error", expanded=True)
                st.error(f"Could not connect to ADK Server at `{ADK_BASE_URL}`. \n\nMake sure you are running: `uv run adk web`")
            except Exception as e:
                status.update(label="Error", state="error", expanded=True)
                st.error(f"An error occurred: {str(e)}")

# --- UI Display Logic ---
def display_agent_result(result: Any):
    """
    Renders the multi-agent pipeline result.
    result is a dict: { agent_name: { full_text, structured }, ... }
    """
    st.markdown("---")

    # --- Handle the grouped-by-agent dict ---
    if isinstance(result, dict) and any(k.endswith("_agent") or k == "unknown" for k in result.keys()):
        
        # Extract each agent's output
        video_data = result.get("video_analyst_agent", {})
        insight_data = result.get("insight_extractor_agent", {})
        creator_data = result.get("creator_agent", {})
        evaluator_data = result.get("evaluator_agent", {})
        
        creator_text = creator_data.get("full_text", "")
        evaluator_text = evaluator_data.get("full_text", "")
        video_json = video_data.get("structured")
        insight_json = insight_data.get("structured")
        
        # --- Check if Evaluator approved ---
        is_approved = False
        eval_rating = "?"
        if "APPROVED" in evaluator_text.upper():
            is_approved = True
        # Try to extract rating
        import re
        rating_match = re.search(r"Rating:\s*(\d+)/10", evaluator_text)
        if rating_match:
            eval_rating = rating_match.group(1)
        
        # ========== HEADER: Approval Status ==========
        if is_approved:
            st.success(f"‚úÖ Content APPROVED by Evaluator Agent ‚Äî Rating: {eval_rating}/10")
        else:
            st.warning(f"‚ö†Ô∏è Content NEEDS REVISION ‚Äî Rating: {eval_rating}/10")
        
        # ========== TABS ==========
        tab_post, tab_eval, tab_analysis, tab_raw = st.tabs([
            "üé® Empfehlung (Creator)", 
            "üìã Evaluation", 
            "üî¨ Video-Analyse",
            "üîç Debug"
        ])
        
        # --- TAB 1: Creator Output (Empfehlungsschreiben) ---
        with tab_post:
            if creator_text:
                st.subheader("ÔøΩ Creator Agent ‚Äì Empfehlung")
                
                # Parse caption from Creator's markdown output
                caption = ""
                hashtags_section = ""
                strategy_section = ""
                trend_section = ""
                
                sections = creator_text.split("##")
                for section in sections:
                    section_lower = section.strip().lower()
                    if section_lower.startswith("caption"):
                        caption = section.split("\n", 1)[-1].strip() if "\n" in section else ""
                    elif section_lower.startswith("strategic hashtag"):
                        hashtags_section = section.split("\n", 1)[-1].strip() if "\n" in section else ""
                    elif section_lower.startswith("strategic justification"):
                        strategy_section = section.split("\n", 1)[-1].strip() if "\n" in section else ""
                    elif section_lower.startswith("trend"):
                        trend_section = section.split("\n", 1)[-1].strip() if "\n" in section else ""
                
                # Display Caption prominently
                if caption:
                    st.markdown("### üí¨ Caption")
                    st.info(strip_urls(caption))
                
                col1, col2 = st.columns(2)
                
                # Display Hashtags
                with col1:
                    if hashtags_section:
                        st.markdown("### üè∑Ô∏è Hashtags & Strategie")
                        st.markdown(strip_urls(hashtags_section))
                
                # Display Trend Research
                with col2:
                    if trend_section:
                        st.markdown("### üìà Trend Research")
                        st.markdown(strip_urls(trend_section))
                
                # Display Strategic Justification
                if strategy_section:
                    st.markdown("### üß† Strategische Begr√ºndung")
                    st.markdown(strip_urls(strategy_section))
                
                # Fallback: show full text if parsing didn't find sections
                if not caption and not hashtags_section:
                    st.markdown(strip_urls(creator_text))
            else:
                st.warning("Kein Creator Agent Output vorhanden.")
        
        # --- TAB 2: Evaluator Output ---
        with tab_eval:
            if evaluator_text:
                st.subheader("üìã Evaluator Agent ‚Äì Bewertung")
                
                if is_approved:
                    st.success(f"**STATUS: APPROVED** ‚Äî Rating: {eval_rating}/10")
                else:
                    st.error(f"**STATUS: NEEDS REVISION** ‚Äî Rating: {eval_rating}/10")
                
                st.markdown(strip_urls(evaluator_text))
            else:
                st.warning("Kein Evaluator Output vorhanden.")
        
        # --- TAB 3: Video Analysis + Insights ---
        with tab_analysis:
            st.subheader("üé¨ Video Analyst")
            if video_json:
                schema = video_json.get("schema_extraction", {})
                st.markdown(f"**Hook Type:**  \n{schema.get('hook_type', 'N/A')}")
                st.markdown("---")
                st.markdown(f"**Scene Length:**  \n{schema.get('scene_length', 'N/A')}")
                st.markdown("---")
                st.markdown(f"**Visual Frequency:**  \n{schema.get('visual_frequency', 'N/A')}")
                st.markdown("---")
                st.markdown(f"**Unique Elements:**  \n{schema.get('unique_visual_elements', 'N/A')}")
                st.markdown("---")
                
                root_qs = video_json.get("root_questions", [])
                if root_qs:
                    st.markdown("**Root Questions:**")
                    for i, q in enumerate(root_qs, 1):
                        st.markdown(f"{i}. {q}")
            elif video_data.get("full_text"):
                st.markdown(strip_urls(video_data["full_text"][:2000]))
            else:
                st.info("Keine Video-Analyse verf√ºgbar.")
            
            st.markdown("---")
            st.subheader("üí° Insight Extractor")
            if insight_json:
                st.markdown(f"**Most Engaging Element:**  \n{insight_json.get('most_engaging_element', 'N/A')}")
                st.markdown("---")
                st.markdown(f"**Hook Strategy:**  \n{insight_json.get('hook_strategy', 'N/A')}")
                st.markdown("---")
                st.markdown(f"**Psychological Angle:**  \n{insight_json.get('psychological_angle', 'N/A')}")
                st.markdown("---")
                st.markdown(f"**Prescriptive Summary:**  \n{insight_json.get('prescriptive_summary', 'N/A')}")
            elif insight_data.get("full_text"):
                st.markdown(strip_urls(insight_data["full_text"][:2000]))
            else:
                st.info("Keine Insights verf√ºgbar.")
        
        # --- TAB 4: Debug Raw ---
        with tab_raw:
            st.json(result)
        
        return
    
    # ========== FALLBACK for old-style results ==========
    st.subheader("ü§ñ Agent Response")
    if isinstance(result, dict):
        st.json(result)
    elif isinstance(result, str):
        st.markdown(result)
    else:
        st.json(result)

# Display Results
if st.session_state.agent_result:
    display_agent_result(st.session_state.agent_result)
    
elif not uploaded_file:
    st.info("üëÜ Please upload a video file to begin.")
</file>

<file path="root_agent/agent.py">
"""
InsightBench Multi-Agent System
================================
A multi-agent pipeline for Social Media Analytics based on the InsightBench framework.

Pipeline:
  1. Video Analyst Agent      (gemini-2.0-flash)  ‚Äì Schema extraction & Root Questions
  2. Insight Extractor Agent  (gemini-2.0-flash)  ‚Äì Multi-step drill-down analysis
  3. Creator Agent            (gemini-2.5-pro)    ‚Äì Prescriptive creative synthesis
  4. Evaluator Agent          (gemini-2.0-flash)  ‚Äì Quality assurance (LLaMA-3-Eval protocol)

The Creator + Evaluator are wrapped in a LoopAgent to retry if the score < 7.
The overall pipeline is orchestrated by a SequentialAgent.
"""

from google.adk.agents import SequentialAgent
from root_agent.subagents import (
    video_analyst_agent,
    insight_extractor_agent,
    creation_evaluation_loop,
)


# ============================================================================
# Root Agent: SequentialAgent orchestrates the full pipeline
# ============================================================================
root_agent = SequentialAgent(
    name="root_agent",
    description="InsightBench Multi-Agent Pipeline: Video Analysis ‚Üí Insight Extraction ‚Üí Creative Synthesis (with evaluation loop).",
    sub_agents=[
        video_analyst_agent,
        insight_extractor_agent,
        creation_evaluation_loop,
    ],
)
</file>

</files>
